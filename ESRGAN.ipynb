{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ESRGAN_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPIm4xM1b0qB1tfXYk+72Qm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhipavi/SRGAN/blob/main/ESRGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLWcOFxid6XF",
        "outputId": "ad217e45-aa83-4873-bef1-03dcc63da6fc"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGSAWMygNNuP"
      },
      "source": [
        "#Convert to TF record"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAM_NGnQNSFV"
      },
      "source": [
        "from absl import app, flags, logging\n",
        "from absl.flags import FLAGS\n",
        "import os\n",
        "import tqdm\n",
        "import glob\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "flags.DEFINE_string('hr_dataset_path', '/content/gdrive/My Drive/BSD100/train',\n",
        "                    'path to high resolution dataset')\n",
        "flags.DEFINE_string('lr_dataset_path', '/content/gdrive/My Drive/BSD100/train_lr',\n",
        "                    'path to low resolution dataset')\n",
        "flags.DEFINE_string('output_path','/content/gdrive/My Drive/BSD100',\n",
        "                    'path to ouput tfrecord')\n",
        "flags.DEFINE_boolean('is_binary', True, 'whether save images as binary files'\n",
        "                     ' or load them on the fly.')\n",
        "\n",
        "\n",
        "def _bytes_feature(value):\n",
        "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
        "    if isinstance(value, type(tf.constant(0))):\n",
        "        value = value.numpy()\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "\n",
        "def _float_feature(value):\n",
        "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
        "\n",
        "\n",
        "def _int64_feature(value):\n",
        "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "\n",
        "def make_example_bin(img_name, hr_img_str, lr_img_str):\n",
        "    # Create a dictionary with features that may be relevant (binary).\n",
        "    feature = {'image/img_name': _bytes_feature(img_name),\n",
        "               'image/hr_encoded': _bytes_feature(hr_img_str),\n",
        "               'image/lr_encoded': _bytes_feature(lr_img_str)}\n",
        "\n",
        "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "\n",
        "def make_example(img_name, hr_img_path, lr_img_path):\n",
        "    # Create a dictionary with features that may be relevant.\n",
        "    feature = {'image/img_name': _bytes_feature(img_name),\n",
        "               'image/hr_img_path': _bytes_feature(hr_img_path),\n",
        "               'image/lr_img_path': _bytes_feature(lr_img_path)}\n",
        "\n",
        "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
        "\n",
        "\n",
        "def main(_):\n",
        "    hr_dataset_path = FLAGS.hr_dataset_path\n",
        "    lr_dataset_path = FLAGS.lr_dataset_path\n",
        "\n",
        "    if not os.path.isdir(hr_dataset_path):\n",
        "        logging.info('Please define valid dataset path.')\n",
        "    else:\n",
        "        logging.info('Loading {}'.format(hr_dataset_path))\n",
        "\n",
        "    samples = []\n",
        "    logging.info('Reading data list...')\n",
        "    for hr_img_path in glob.glob(os.path.join(hr_dataset_path, '*.png')):\n",
        "        img_name = os.path.basename(hr_img_path).replace('.png', '')\n",
        "        lr_img_path = os.path.join(lr_dataset_path, img_name + '.png')\n",
        "        samples.append((img_name, hr_img_path, lr_img_path))\n",
        "    random.shuffle(samples)\n",
        "\n",
        "    if os.path.exists(FLAGS.output_path):\n",
        "        logging.info('{:s} already exists. Exit...'.format(\n",
        "            FLAGS.output_path))\n",
        "        exit(1)\n",
        "\n",
        "    logging.info('Writing {} sample to tfrecord file...'.format(len(samples)))\n",
        "    with tf.io.TFRecordWriter(FLAGS.output_path) as writer:\n",
        "        for img_name, hr_img_path, lr_img_path in tqdm.tqdm(samples):\n",
        "            if FLAGS.is_binary:\n",
        "                hr_img_str = open(hr_img_path, 'rb').read()\n",
        "                lr_img_str = open(lr_img_path, 'rb').read()\n",
        "                tf_example = make_example_bin(img_name=str.encode(img_name),\n",
        "                                              hr_img_str=hr_img_str,\n",
        "                                              lr_img_str=lr_img_str)\n",
        "            else:\n",
        "                tf_example = make_example(img_name=str.encode(img_name),\n",
        "                                          hr_img_path=str.encode(hr_img_path),\n",
        "                                          lr_img_path=str.encode(lr_img_path))\n",
        "            writer.write(tf_example.SerializeToString())\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    try:\n",
        "        app.run(main)\n",
        "    except SystemExit:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLCXYqaMxacX"
      },
      "source": [
        "# Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7-3uYUCxYkk"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg19 import preprocess_input, VGG19\n",
        "\n",
        "\n",
        "def PixelLoss(criterion='l1'):\n",
        "    \"\"\"pixel loss\"\"\"\n",
        "    if criterion == 'l1':\n",
        "        return tf.keras.losses.MeanAbsoluteError()\n",
        "    elif criterion == 'l2':\n",
        "        return tf.keras.losses.MeanSquaredError()\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'Loss type {} is not recognized.'.format(criterion))\n",
        "\n",
        "\n",
        "def ContentLoss(criterion='l1', output_layer=54, before_act=True):\n",
        "    \"\"\"content loss\"\"\"\n",
        "    if criterion == 'l1':\n",
        "        loss_func = tf.keras.losses.MeanAbsoluteError()\n",
        "    elif criterion == 'l2':\n",
        "        loss_func = tf.keras.losses.MeanSquaredError()\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'Loss type {} is not recognized.'.format(criterion))\n",
        "    vgg = VGG19(input_shape=(None, None, 3), include_top=False)\n",
        "\n",
        "    if output_layer == 22:  # Low level feature\n",
        "        pick_layer = 5\n",
        "    elif output_layer == 54:  # Hight level feature\n",
        "        pick_layer = 20\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'VGG output layer {} is not recognized.'.format(criterion))\n",
        "\n",
        "    if before_act:\n",
        "        vgg.layers[pick_layer].activation = None\n",
        "\n",
        "    fea_extrator = tf.keras.Model(vgg.input, vgg.layers[pick_layer].output)\n",
        "\n",
        "    @tf.function\n",
        "    def content_loss(hr, sr):\n",
        "        # the input scale range is [0, 1] (vgg is [0, 255]).\n",
        "        # 12.75 is rescale factor for vgg featuremaps.\n",
        "        preprocess_sr = preprocess_input(sr * 255.) / 12.75\n",
        "        preprocess_hr = preprocess_input(hr * 255.) / 12.75\n",
        "        sr_features = fea_extrator(preprocess_sr)\n",
        "        hr_features = fea_extrator(preprocess_hr)\n",
        "\n",
        "        return loss_func(hr_features, sr_features)\n",
        "\n",
        "    return content_loss\n",
        "\n",
        "\n",
        "def DiscriminatorLoss(gan_type='ragan'):\n",
        "    \"\"\"discriminator loss\"\"\"\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    sigma = tf.sigmoid\n",
        "\n",
        "    def discriminator_loss_ragan(hr, sr):\n",
        "        return 0.5 * (\n",
        "            cross_entropy(tf.ones_like(hr), sigma(hr - tf.reduce_mean(sr))) +\n",
        "            cross_entropy(tf.zeros_like(sr), sigma(sr - tf.reduce_mean(hr))))\n",
        "\n",
        "    def discriminator_loss(hr, sr):\n",
        "        real_loss = cross_entropy(tf.ones_like(hr), sigma(hr))\n",
        "        fake_loss = cross_entropy(tf.zeros_like(sr), sigma(sr))\n",
        "        return real_loss + fake_loss\n",
        "\n",
        "    if gan_type == 'ragan':\n",
        "        return discriminator_loss_ragan\n",
        "    elif gan_type == 'gan':\n",
        "        return discriminator_loss\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'Discriminator loss type {} is not recognized.'.format(gan_type))\n",
        "\n",
        "\n",
        "def GeneratorLoss(gan_type='ragan'):\n",
        "    \"\"\"generator loss\"\"\"\n",
        "    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "    sigma = tf.sigmoid\n",
        "\n",
        "    def generator_loss_ragan(hr, sr):\n",
        "        return 0.5 * (\n",
        "            cross_entropy(tf.ones_like(sr), sigma(sr - tf.reduce_mean(hr))) +\n",
        "            cross_entropy(tf.zeros_like(hr), sigma(hr - tf.reduce_mean(sr))))\n",
        "\n",
        "    def generator_loss(hr, sr):\n",
        "        return cross_entropy(tf.ones_like(sr), sigma(sr))\n",
        "\n",
        "    if gan_type == 'ragan':\n",
        "        return generator_loss_ragan\n",
        "    elif gan_type == 'gan':\n",
        "        return generator_loss\n",
        "    else:\n",
        "        raise NotImplementedError(\n",
        "            'Generator loss type {} is not recognized.'.format(gan_type))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lw6bHX6zzVy"
      },
      "source": [
        "#LR Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxulPv9_z1YK"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def MultiStepLR(initial_learning_rate, lr_steps, lr_rate, name='MultiStepLR'):\n",
        "    \"\"\"Multi-steps learning rate scheduler.\"\"\"\n",
        "    lr_steps_value = [initial_learning_rate]\n",
        "    for _ in range(len(lr_steps)):\n",
        "        lr_steps_value.append(lr_steps_value[-1] * lr_rate)\n",
        "    return tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "        boundaries=lr_steps, values=lr_steps_value)\n",
        "\n",
        "\n",
        "def CosineAnnealingLR_Restart(initial_learning_rate, t_period, lr_min):\n",
        "    \"\"\"Cosine annealing learning rate scheduler with restart.\"\"\"\n",
        "    return tf.keras.experimental.CosineDecayRestarts(\n",
        "        initial_learning_rate=initial_learning_rate,\n",
        "        first_decay_steps=t_period, t_mul=1.0, m_mul=1.0,\n",
        "        alpha=lr_min / initial_learning_rate)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # pretrain PSNR lr scheduler\n",
        "    lr_scheduler = MultiStepLR(2e-4, [200000, 400000, 600000, 800000], 0.5)\n",
        "\n",
        "    # ESRGAN lr scheduler\n",
        "    # lr_scheduler = MultiStepLR(1e-4, [50000, 100000, 200000, 300000], 0.5)\n",
        "\n",
        "    # Cosine Annealing lr scheduler\n",
        "    # lr_scheduler = CosineAnnealingLR_Restart(2e-4, 250000, 1e-7)\n",
        "\n",
        "    ##############################\n",
        "    # Draw figure\n",
        "    ##############################\n",
        "    N_iter = 1000000\n",
        "    step_list = list(range(0, N_iter, 1000))\n",
        "    lr_list = []\n",
        "    for i in step_list:\n",
        "        current_lr = lr_scheduler(i).numpy()\n",
        "        lr_list.append(current_lr)\n",
        "\n",
        "    import matplotlib as mpl\n",
        "    from matplotlib import pyplot as plt\n",
        "    import matplotlib.ticker as mtick\n",
        "    mpl.style.use('default')\n",
        "    import seaborn\n",
        "    seaborn.set(style='whitegrid')\n",
        "    seaborn.set_context('paper')\n",
        "\n",
        "    plt.figure(1)\n",
        "    plt.subplot(111)\n",
        "    plt.ticklabel_format(style='sci', axis='x', scilimits=(0, 0))\n",
        "    plt.title('Title', fontsize=16, color='k')\n",
        "    plt.plot(step_list, lr_list, linewidth=1.5, label='learning rate scheme')\n",
        "    legend = plt.legend(loc='upper right', shadow=False)\n",
        "    ax = plt.gca()\n",
        "    labels = ax.get_xticks().tolist()\n",
        "    for k, v in enumerate(labels):\n",
        "        labels[k] = str(int(v / 1000)) + 'K'\n",
        "    ax.set_xticklabels(labels)\n",
        "    ax.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.1e'))\n",
        "\n",
        "    ax.set_ylabel('Learning rate')\n",
        "    ax.set_xlabel('Iteration')\n",
        "    fig = plt.gcf()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smSEJ-OQzmbd"
      },
      "source": [
        "#Utilities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qn5nyKvzoDm"
      },
      "source": [
        "import cv2\n",
        "import yaml\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from absl import logging\n",
        "from modules.dataset import load_tfrecord_dataset\n",
        "\n",
        "\n",
        "def load_yaml(load_path):\n",
        "    \"\"\"load yaml file\"\"\"\n",
        "    with open(load_path, 'r') as f:\n",
        "        loaded = yaml.load(f, Loader=yaml.Loader)\n",
        "\n",
        "    return loaded\n",
        "\n",
        "\n",
        "def set_memory_growth():\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    if gpus:\n",
        "        try:\n",
        "            # Currently, memory growth needs to be the same across GPUs\n",
        "            for gpu in gpus:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "                logical_gpus = tf.config.experimental.list_logical_devices(\n",
        "                    'GPU')\n",
        "                logging.info(\n",
        "                    \"Detect {} Physical GPUs, {} Logical GPUs.\".format(\n",
        "                        len(gpus), len(logical_gpus)))\n",
        "        except RuntimeError as e:\n",
        "            # Memory growth must be set before GPUs have been initialized\n",
        "            logging.info(e)\n",
        "\n",
        "\n",
        "def load_dataset(cfg, key, shuffle=True, buffer_size=10240):\n",
        "    \"\"\"load dataset\"\"\"\n",
        "    dataset_cfg = cfg[key]\n",
        "    logging.info(\"load {} from {}\".format(key, dataset_cfg['path']))\n",
        "    dataset = load_tfrecord_dataset(\n",
        "        tfrecord_name=dataset_cfg['path'],\n",
        "        batch_size=cfg['batch_size'],\n",
        "        gt_size=cfg['gt_size'],\n",
        "        scale=cfg['scale'],\n",
        "        shuffle=shuffle,\n",
        "        using_bin=dataset_cfg['using_bin'],\n",
        "        using_flip=dataset_cfg['using_flip'],\n",
        "        using_rot=dataset_cfg['using_rot'],\n",
        "        buffer_size=buffer_size)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def create_lr_hr_pair(raw_img, scale=4.):\n",
        "    lr_h, lr_w = raw_img.shape[0] // scale, raw_img.shape[1] // scale\n",
        "    hr_h, hr_w = lr_h * scale, lr_w * scale\n",
        "    hr_img = raw_img[:hr_h, :hr_w, :]\n",
        "    lr_img = imresize_np(hr_img, 1 / scale)\n",
        "    return lr_img, hr_img\n",
        "\n",
        "\n",
        "def tensor2img(tensor):\n",
        "    return (np.squeeze(tensor.numpy()).clip(0, 1) * 255).astype(np.uint8)\n",
        "\n",
        "\n",
        "def change_weight(model, vars1, vars2, alpha=1.0):\n",
        "    for i, var in enumerate(model.trainable_variables):\n",
        "        var.assign((1 - alpha) * vars1[i] + alpha * vars2[i])\n",
        "\n",
        "\n",
        "class ProgressBar(object):\n",
        "    \"\"\"A progress bar which can print the progress modified from\n",
        "       https://github.com/hellock/cvbase/blob/master/cvbase/progress.py\"\"\"\n",
        "    def __init__(self, task_num=0, completed=0, bar_width=25):\n",
        "        self.task_num = task_num\n",
        "        max_bar_width = self._get_max_bar_width()\n",
        "        self.bar_width = (bar_width\n",
        "                          if bar_width <= max_bar_width else max_bar_width)\n",
        "        self.completed = completed\n",
        "        self.first_step = completed\n",
        "        self.warm_up = False\n",
        "\n",
        "    def _get_max_bar_width(self):\n",
        "        if sys.version_info > (3, 3):\n",
        "            from shutil import get_terminal_size\n",
        "        else:\n",
        "            from backports.shutil_get_terminal_size import get_terminal_size\n",
        "        terminal_width, _ = get_terminal_size()\n",
        "        max_bar_width = min(int(terminal_width * 0.6), terminal_width - 50)\n",
        "        if max_bar_width < 10:\n",
        "            logging.info('terminal width is too small ({}), please consider '\n",
        "                         'widen the terminal for better progressbar '\n",
        "                         'visualization'.format(terminal_width))\n",
        "            max_bar_width = 10\n",
        "        return max_bar_width\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"reset\"\"\"\n",
        "        self.completed = 0\n",
        "\n",
        "    def update(self, inf_str=''):\n",
        "        \"\"\"update\"\"\"\n",
        "        self.completed += 1\n",
        "        if not self.warm_up:\n",
        "            self.start_time = time.time() - 1e-2\n",
        "            self.warm_up = True\n",
        "        elapsed = time.time() - self.start_time\n",
        "        fps = (self.completed - self.first_step) / elapsed\n",
        "        percentage = self.completed / float(self.task_num)\n",
        "        mark_width = int(self.bar_width * percentage)\n",
        "        bar_chars = '>' * mark_width + ' ' * (self.bar_width - mark_width)\n",
        "        stdout_str = \\\n",
        "            '\\rTraining [{}] {}/{}, {}  {:.1f} step/sec'\n",
        "        sys.stdout.write(stdout_str.format(\n",
        "            bar_chars, self.completed, self.task_num, inf_str, fps))\n",
        "\n",
        "        sys.stdout.flush()\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "#   These processing code is copied and modified from official implement:     #\n",
        "#    https://github.com/open-mmlab/mmsr                                       #\n",
        "###############################################################################\n",
        "def imresize_np(img, scale, antialiasing=True):\n",
        "    # Now the scale should be the same for H and W\n",
        "    # input: img: Numpy, HWC RBG [0,1]\n",
        "    # output: HWC RBG [0,1] w/o round\n",
        "    # (Modified from\n",
        "    #  https://github.com/open-mmlab/mmsr/blob/master/codes/data/util.py)\n",
        "    in_H, in_W, in_C = img.shape\n",
        "\n",
        "    _, out_H, out_W = in_C, np.ceil(in_H * scale), np.ceil(in_W * scale)\n",
        "    out_H, out_W = out_H.astype(np.int64), out_W.astype(np.int64)\n",
        "    kernel_width = 4\n",
        "    kernel = 'cubic'\n",
        "\n",
        "    # Return the desired dimension order for performing the resize.  The\n",
        "    # strategy is to perform the resize first along the dimension with the\n",
        "    # smallest scale factor.\n",
        "    # Now we do not support this.\n",
        "\n",
        "    # get weights and indices\n",
        "    weights_H, indices_H, sym_len_Hs, sym_len_He = _calculate_weights_indices(\n",
        "        in_H, out_H, scale, kernel, kernel_width, antialiasing)\n",
        "    weights_W, indices_W, sym_len_Ws, sym_len_We = _calculate_weights_indices(\n",
        "        in_W, out_W, scale, kernel, kernel_width, antialiasing)\n",
        "    # process H dimension\n",
        "    # symmetric copying\n",
        "    img_aug = np.zeros(((in_H + sym_len_Hs + sym_len_He), in_W, in_C))\n",
        "    img_aug[sym_len_Hs:sym_len_Hs + in_H] = img\n",
        "\n",
        "    sym_patch = img[:sym_len_Hs, :, :]\n",
        "    sym_patch_inv = sym_patch[::-1]\n",
        "    img_aug[0:sym_len_Hs] = sym_patch_inv\n",
        "\n",
        "    sym_patch = img[-sym_len_He:, :, :]\n",
        "    sym_patch_inv = sym_patch[::-1]\n",
        "    img_aug[sym_len_Hs + in_H:sym_len_Hs + in_H + sym_len_He] = sym_patch_inv\n",
        "\n",
        "    out_1 = np.zeros((out_H, in_W, in_C))\n",
        "    kernel_width = weights_H.shape[1]\n",
        "    for i in range(out_H):\n",
        "        idx = int(indices_H[i][0])\n",
        "        out_1[i, :, 0] = weights_H[i].dot(\n",
        "            img_aug[idx:idx + kernel_width, :, 0].transpose(0, 1))\n",
        "        out_1[i, :, 1] = weights_H[i].dot(\n",
        "            img_aug[idx:idx + kernel_width, :, 1].transpose(0, 1))\n",
        "        out_1[i, :, 2] = weights_H[i].dot(\n",
        "            img_aug[idx:idx + kernel_width, :, 2].transpose(0, 1))\n",
        "\n",
        "    # process W dimension\n",
        "    # symmetric copying\n",
        "    out_1_aug = np.zeros((out_H, in_W + sym_len_Ws + sym_len_We, in_C))\n",
        "    out_1_aug[:, sym_len_Ws:sym_len_Ws + in_W] = out_1\n",
        "\n",
        "    sym_patch = out_1[:, :sym_len_Ws, :]\n",
        "    sym_patch_inv = sym_patch[:, ::-1]\n",
        "    out_1_aug[:, 0:sym_len_Ws] = sym_patch_inv\n",
        "\n",
        "    sym_patch = out_1[:, -sym_len_We:, :]\n",
        "    sym_patch_inv = sym_patch[:, ::-1]\n",
        "    out_1_aug[:, sym_len_Ws + in_W:sym_len_Ws + in_W + sym_len_We] = \\\n",
        "        sym_patch_inv\n",
        "\n",
        "    out_2 = np.zeros((out_H, out_W, in_C))\n",
        "    kernel_width = weights_W.shape[1]\n",
        "    for i in range(out_W):\n",
        "        idx = int(indices_W[i][0])\n",
        "        out_2[:, i, 0] = out_1_aug[:, idx:idx + kernel_width, 0].dot(\n",
        "            weights_W[i])\n",
        "        out_2[:, i, 1] = out_1_aug[:, idx:idx + kernel_width, 1].dot(\n",
        "            weights_W[i])\n",
        "        out_2[:, i, 2] = out_1_aug[:, idx:idx + kernel_width, 2].dot(\n",
        "            weights_W[i])\n",
        "\n",
        "    return out_2.clip(0, 255)\n",
        "\n",
        "\n",
        "def _cubic(x):\n",
        "    absx = np.abs(x)\n",
        "    absx2 = absx ** 2\n",
        "    absx3 = absx ** 3\n",
        "    return (1.5 * absx3 - 2.5 * absx2 + 1) * ((absx <= 1).astype(np.float64)) \\\n",
        "        + (-0.5 * absx3 + 2.5 * absx2 - 4 * absx + 2) * (\n",
        "            ((absx > 1) * (absx <= 2)).astype(np.float64))\n",
        "\n",
        "\n",
        "def _calculate_weights_indices(in_length, out_length, scale, kernel,\n",
        "                               kernel_width, antialiasing):\n",
        "    if (scale < 1) and (antialiasing):\n",
        "        # Use a modified kernel to simultaneously interpolate and antialias\n",
        "        # larger kernel width\n",
        "        kernel_width = kernel_width / scale\n",
        "\n",
        "    # Output-space coordinates\n",
        "    x = np.linspace(1, out_length, out_length)\n",
        "\n",
        "    # Input-space coordinates. Calculate the inverse mapping such that 0.5\n",
        "    # in output space maps to 0.5 in input space, and 0.5+scale in output\n",
        "    # space maps to 1.5 in input space.\n",
        "    u = x / scale + 0.5 * (1 - 1 / scale)\n",
        "\n",
        "    # What is the left-most pixel that can be involved in the computation?\n",
        "    left = np.floor(u - kernel_width / 2)\n",
        "\n",
        "    # What is the maximum number of pixels that can be involved in the\n",
        "    # computation?  Note: it's OK to use an extra pixel here; if the\n",
        "    # corresponding weights are all zero, it will be eliminated at the end\n",
        "    # of this function.\n",
        "    P = (np.ceil(kernel_width) + 2).astype(np.int32)\n",
        "\n",
        "    # The indices of the input pixels involved in computing the k-th output\n",
        "    # pixel are in row k of the indices matrix.\n",
        "    indices = left.reshape(int(out_length), 1).repeat(P, axis=1) + \\\n",
        "        np.linspace(0, P - 1, P).reshape(1, int(P)).repeat(out_length, axis=0)\n",
        "\n",
        "    # The weights used to compute the k-th output pixel are in row k of the\n",
        "    # weights matrix.\n",
        "    distance_to_center = \\\n",
        "        u.reshape(int(out_length), 1).repeat(P, axis=1) - indices\n",
        "    # apply cubic kernel\n",
        "    if (scale < 1) and (antialiasing):\n",
        "        weights = scale * _cubic(distance_to_center * scale)\n",
        "    else:\n",
        "        weights = _cubic(distance_to_center)\n",
        "    # Normalize the weights matrix so that each row sums to 1.\n",
        "    weights_sum = np.sum(weights, 1).reshape(int(out_length), 1)\n",
        "    weights = weights / weights_sum.repeat(P, axis=1)\n",
        "\n",
        "    # If a column in weights is all zero, get rid of it. only consider the\n",
        "    # first and last column.\n",
        "    weights_zero_tmp = np.sum((weights == 0), 0)\n",
        "    if not np.isclose(weights_zero_tmp[0], 0, rtol=1e-6):\n",
        "        indices = indices[:, 1:1 + int(P) - 2]\n",
        "        weights = weights[:, 1:1 + int(P) - 2]\n",
        "    if not np.isclose(weights_zero_tmp[-1], 0, rtol=1e-6):\n",
        "        indices = indices[:, 0:0 + int(P) - 2]\n",
        "        weights = weights[:, 0:0 + int(P) - 2]\n",
        "    weights = weights.copy()\n",
        "    indices = indices.copy()\n",
        "    sym_len_s = -indices.min() + 1\n",
        "    sym_len_e = indices.max() - in_length\n",
        "    indices = indices + sym_len_s - 1\n",
        "    return weights, indices, int(sym_len_s), int(sym_len_e)\n",
        "\n",
        "\n",
        "def calculate_psnr(img1, img2):\n",
        "    # img1 and img2 have range [0, 255]\n",
        "    img1 = img1.astype(np.float64)\n",
        "    img2 = img2.astype(np.float64)\n",
        "    mse = np.mean((img1 - img2)**2)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    return 20 * np.log10(255.0 / np.sqrt(mse))\n",
        "\n",
        "\n",
        "def _ssim(img1, img2):\n",
        "    C1 = (0.01 * 255)**2\n",
        "    C2 = (0.03 * 255)**2\n",
        "\n",
        "    img1 = img1.astype(np.float64)\n",
        "    img2 = img2.astype(np.float64)\n",
        "    kernel = cv2.getGaussianKernel(11, 1.5)\n",
        "    window = np.outer(kernel, kernel.transpose())\n",
        "\n",
        "    mu1 = cv2.filter2D(img1, -1, window)[5:-5, 5:-5]  # valid\n",
        "    mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n",
        "    mu1_sq = mu1**2\n",
        "    mu2_sq = mu2**2\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "    sigma1_sq = cv2.filter2D(img1**2, -1, window)[5:-5, 5:-5] - mu1_sq\n",
        "    sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n",
        "    sigma12 = cv2.filter2D(img1 * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n",
        "\n",
        "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) \\\n",
        "        / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
        "    return ssim_map.mean()\n",
        "\n",
        "\n",
        "def calculate_ssim(img1, img2):\n",
        "    '''calculate SSIM\n",
        "    the same outputs as MATLAB's\n",
        "    img1, img2: [0, 255]\n",
        "    '''\n",
        "    if not img1.shape == img2.shape:\n",
        "        raise ValueError('Input images must have the same dimensions.')\n",
        "    if img1.ndim == 2:\n",
        "        return _ssim(img1, img2)\n",
        "    elif img1.ndim == 3:\n",
        "        if img1.shape[2] == 3:\n",
        "            ssims = []\n",
        "            for _ in range(3):\n",
        "                ssims.append(_ssim(img1, img2))\n",
        "            return np.array(ssims).mean()\n",
        "        elif img1.shape[2] == 1:\n",
        "            return _ssim(np.squeeze(img1), np.squeeze(img2))\n",
        "    else:\n",
        "        raise ValueError('Wrong input image dimensions.')\n",
        "\n",
        "\n",
        "def rgb2ycbcr(img, only_y=True):\n",
        "    \"\"\"Convert rgb to ycbcr\n",
        "    only_y: only return Y channel\n",
        "    Input:\n",
        "        uint8, [0, 255]\n",
        "        float, [0, 1]\n",
        "    \"\"\"\n",
        "    in_img_type = img.dtype\n",
        "    img.astype(np.float32)\n",
        "    if in_img_type != np.uint8:\n",
        "        img *= 255.\n",
        "    img = img[:, :, ::-1]\n",
        "\n",
        "    # convert\n",
        "    if only_y:\n",
        "        rlt = np.dot(img, [24.966, 128.553, 65.481]) / 255.0 + 16.0\n",
        "    else:\n",
        "        rlt = np.matmul(\n",
        "            img, [[24.966, 112.0, -18.214],\n",
        "                  [128.553, -74.203, -93.786],\n",
        "                  [65.481, -37.797, 112.0]]) / 255.0 + [16, 128, 128]\n",
        "    if in_img_type == np.uint8:\n",
        "        rlt = rlt.round()\n",
        "    else:\n",
        "        rlt /= 255.\n",
        "    return rlt.astype(in_img_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PC2WqpLpxWyN"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GVku1Mgw8rn"
      },
      "source": [
        "import functools\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Input, Conv2D, LeakyReLU\n",
        "\n",
        "\n",
        "def _regularizer(weights_decay=5e-4):\n",
        "    return tf.keras.regularizers.l2(weights_decay)\n",
        "\n",
        "\n",
        "def _kernel_init(scale=1.0, seed=None):\n",
        "    scale = 2. * scale\n",
        "    return tf.keras.initializers.VarianceScaling(\n",
        "        scale=scale, mode='fan_in', distribution=\"truncated_normal\", seed=seed)\n",
        "\n",
        "\n",
        "class BatchNormalization(tf.keras.layers.BatchNormalization):\n",
        "    def __init__(self, axis=-1, momentum=0.9, epsilon=1e-5, center=True,\n",
        "                 scale=True, name=None, **kwargs):\n",
        "        super(BatchNormalization, self).__init__(\n",
        "            axis=axis, momentum=momentum, epsilon=epsilon, center=center,\n",
        "            scale=scale, name=name, **kwargs)\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        if training is None:\n",
        "            training = tf.constant(False)\n",
        "        training = tf.logical_and(training, self.trainable)\n",
        "        return super().call(x, training)\n",
        "\n",
        "\n",
        "class ResDenseBlock_5C(tf.keras.layers.Layer):\n",
        "    \"\"\"Residual Dense Block\"\"\"\n",
        "    def __init__(self, nf=64, gc=32, res_beta=0.2, wd=0., name='RDB5C',\n",
        "                 **kwargs):\n",
        "        super(ResDenseBlock_5C, self).__init__(name=name, **kwargs)\n",
        "        # gc: growth channel, i.e. intermediate channels\n",
        "        self.res_beta = res_beta\n",
        "        lrelu_f = functools.partial(LeakyReLU, alpha=0.2)\n",
        "        _Conv2DLayer = functools.partial(\n",
        "            Conv2D, kernel_size=3, padding='same',\n",
        "            kernel_initializer=_kernel_init(0.1), bias_initializer='zeros',\n",
        "            kernel_regularizer=_regularizer(wd))\n",
        "        self.conv1 = _Conv2DLayer(filters=gc, activation=lrelu_f())\n",
        "        self.conv2 = _Conv2DLayer(filters=gc, activation=lrelu_f())\n",
        "        self.conv3 = _Conv2DLayer(filters=gc, activation=lrelu_f())\n",
        "        self.conv4 = _Conv2DLayer(filters=gc, activation=lrelu_f())\n",
        "        self.conv5 = _Conv2DLayer(filters=nf, activation=lrelu_f())\n",
        "\n",
        "    def call(self, x):\n",
        "        x1 = self.conv1(x)\n",
        "        x2 = self.conv2(tf.concat([x, x1], 3))\n",
        "        x3 = self.conv3(tf.concat([x, x1, x2], 3))\n",
        "        x4 = self.conv4(tf.concat([x, x1, x2, x3], 3))\n",
        "        x5 = self.conv5(tf.concat([x, x1, x2, x3, x4], 3))\n",
        "        return x5 * self.res_beta + x\n",
        "\n",
        "\n",
        "class ResInResDenseBlock(tf.keras.layers.Layer):\n",
        "    \"\"\"Residual in Residual Dense Block\"\"\"\n",
        "    def __init__(self, nf=64, gc=32, res_beta=0.2, wd=0., name='RRDB',\n",
        "                 **kwargs):\n",
        "        super(ResInResDenseBlock, self).__init__(name=name, **kwargs)\n",
        "        self.res_beta = res_beta\n",
        "        self.rdb_1 = ResDenseBlock_5C(nf, gc, res_beta=res_beta, wd=wd)\n",
        "        self.rdb_2 = ResDenseBlock_5C(nf, gc, res_beta=res_beta, wd=wd)\n",
        "        self.rdb_3 = ResDenseBlock_5C(nf, gc, res_beta=res_beta, wd=wd)\n",
        "\n",
        "    def call(self, x):\n",
        "        out = self.rdb_1(x)\n",
        "        out = self.rdb_2(out)\n",
        "        out = self.rdb_3(out)\n",
        "        return out * self.res_beta + x\n",
        "\n",
        "\n",
        "def RRDB_Model(size, channels, cfg_net, gc=32, wd=0., name='RRDB_model'):\n",
        "    \"\"\"Residual-in-Residual Dense Block based Model \"\"\"\n",
        "    nf, nb = cfg_net['nf'], cfg_net['nb']\n",
        "    lrelu_f = functools.partial(LeakyReLU, alpha=0.2)\n",
        "    rrdb_f = functools.partial(ResInResDenseBlock, nf=nf, gc=gc, wd=wd)\n",
        "    conv_f = functools.partial(Conv2D, kernel_size=3, padding='same',\n",
        "                               bias_initializer='zeros',\n",
        "                               kernel_initializer=_kernel_init(),\n",
        "                               kernel_regularizer=_regularizer(wd))\n",
        "    rrdb_truck_f = tf.keras.Sequential(\n",
        "        [rrdb_f(name=\"RRDB_{}\".format(i)) for i in range(nb)],\n",
        "        name='RRDB_trunk')\n",
        "\n",
        "    # extraction\n",
        "    x = inputs = Input([size, size, channels], name='input_image')\n",
        "    fea = conv_f(filters=nf, name='conv_first')(x)\n",
        "    fea_rrdb = rrdb_truck_f(fea)\n",
        "    trunck = conv_f(filters=nf, name='conv_trunk')(fea_rrdb)\n",
        "    fea = fea + trunck\n",
        "\n",
        "    # upsampling\n",
        "    size_fea_h = tf.shape(fea)[1] if size is None else size\n",
        "    size_fea_w = tf.shape(fea)[2] if size is None else size\n",
        "    fea_resize = tf.image.resize(fea, [size_fea_h * 2, size_fea_w * 2],\n",
        "                                 method='nearest', name='upsample_nn_1')\n",
        "    fea = conv_f(filters=nf, activation=lrelu_f(), name='upconv_1')(fea_resize)\n",
        "    fea_resize = tf.image.resize(fea, [size_fea_h * 4, size_fea_w * 4],\n",
        "                                 method='nearest', name='upsample_nn_2')\n",
        "    fea = conv_f(filters=nf, activation=lrelu_f(), name='upconv_2')(fea_resize)\n",
        "    fea = conv_f(filters=nf, activation=lrelu_f(), name='conv_hr')(fea)\n",
        "    out = conv_f(filters=channels, name='conv_last')(fea)\n",
        "\n",
        "    return Model(inputs, out, name=name)\n",
        "\n",
        "\n",
        "def DiscriminatorVGG128(size, channels, nf=64, wd=0.,\n",
        "                        name='Discriminator_VGG_128'):\n",
        "    \"\"\"Discriminator VGG 128\"\"\"\n",
        "    lrelu_f = functools.partial(LeakyReLU, alpha=0.2)\n",
        "    conv_k3s1_f = functools.partial(Conv2D,\n",
        "                                    kernel_size=3, strides=1, padding='same',\n",
        "                                    kernel_initializer=_kernel_init(),\n",
        "                                    kernel_regularizer=_regularizer(wd))\n",
        "    conv_k4s2_f = functools.partial(Conv2D,\n",
        "                                    kernel_size=4, strides=2, padding='same',\n",
        "                                    kernel_initializer=_kernel_init(),\n",
        "                                    kernel_regularizer=_regularizer(wd))\n",
        "    dese_f = functools.partial(Dense, kernel_regularizer=_regularizer(wd))\n",
        "\n",
        "    x = inputs = Input(shape=(size, size, channels))\n",
        "\n",
        "    x = conv_k3s1_f(filters=nf, name='conv0_0')(x)\n",
        "    x = conv_k4s2_f(filters=nf, use_bias=False, name='conv0_1')(x)\n",
        "    x = lrelu_f()(BatchNormalization(name='bn0_1')(x))\n",
        "\n",
        "    x = conv_k3s1_f(filters=nf * 2, use_bias=False, name='conv1_0')(x)\n",
        "    x = lrelu_f()(BatchNormalization(name='bn1_0')(x))\n",
        "    x = conv_k4s2_f(filters=nf * 2, use_bias=False, name='conv1_1')(x)\n",
        "    x = lrelu_f()(BatchNormalization(name='bn1_1')(x))\n",
        "\n",
        "    x = conv_k3s1_f(filters=nf * 4, use_bias=False, name='conv2_0')(x)\n",
        "    x = lrelu_f()(BatchNormalization(name='bn2_0')(x))\n",
        "    x = conv_k4s2_f(filters=nf * 4, use_bias=False, name='conv2_1')(x)\n",
        "    x = lrelu_f()(BatchNormalization(name='bn2_1')(x))\n",
        "\n",
        "    x = conv_k3s1_f(filters=nf * 8, use_bias=False, name='conv3_0')(x)\n",
        "    x = lrelu_f()(BatchNormalization(name='bn3_0')(x))\n",
        "    x = conv_k4s2_f(filters=nf * 8, use_bias=False, name='conv3_1')(x)\n",
        "    x = lrelu_f()(BatchNormalization(name='bn3_1')(x))\n",
        "\n",
        "    x = conv_k3s1_f(filters=nf * 8, use_bias=False, name='conv4_0')(x)\n",
        "    x = lrelu_f()(BatchNormalization(name='bn4_0')(x))\n",
        "    x = conv_k4s2_f(filters=nf * 8, use_bias=False, name='conv4_1')(x)\n",
        "    x = lrelu_f()(BatchNormalization(name='bn4_1')(x))\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = dese_f(units=100, activation=lrelu_f(), name='linear1')(x)\n",
        "    out = dese_f(units=1, name='linear2')(x)\n",
        "\n",
        "    return Model(inputs, out, name=name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPDRq4SGzMs1"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_Q-WGaqzYWy"
      },
      "source": [
        "from absl import app, flags, logging\n",
        "from absl.flags import FLAGS\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "#from modules.models import RRDB_Model, DiscriminatorVGG128\n",
        "#from modules.lr_scheduler import MultiStepLR\n",
        "#from modules.losses import (PixelLoss, ContentLoss, DiscriminatorLoss,\n",
        "#                            GeneratorLoss)\n",
        "#from modules.utils import (load_yaml, load_dataset, ProgressBar,\n",
        "#                           set_memory_growth)\n",
        "\n",
        "\n",
        "flags.DEFINE_string('cfg_path', './configs/esrgan.yaml', 'config file path')\n",
        "flags.DEFINE_string('gpu', '0', 'which gpu to use')\n",
        "\n",
        "\n",
        "def main(_):\n",
        "    # init\n",
        "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = FLAGS.gpu\n",
        "\n",
        "    logger = tf.get_logger()\n",
        "    logger.disabled = True\n",
        "    logger.setLevel(logging.FATAL)\n",
        "    set_memory_growth()\n",
        "\n",
        "    cfg = load_yaml(FLAGS.cfg_path)\n",
        "\n",
        "    # define network\n",
        "    generator = RRDB_Model(cfg['input_size'], cfg['ch_size'], cfg['network_G'])\n",
        "    generator.summary(line_length=80)\n",
        "    discriminator = DiscriminatorVGG128(cfg['gt_size'], cfg['ch_size'])\n",
        "    discriminator.summary(line_length=80)\n",
        "\n",
        "    # load dataset\n",
        "    train_dataset = load_dataset(cfg, 'train_dataset', shuffle=False)\n",
        "\n",
        "    # define optimizer\n",
        "    learning_rate_G = MultiStepLR(cfg['lr_G'], cfg['lr_steps'], cfg['lr_rate'])\n",
        "    learning_rate_D = MultiStepLR(cfg['lr_D'], cfg['lr_steps'], cfg['lr_rate'])\n",
        "    optimizer_G = tf.keras.optimizers.Adam(learning_rate=learning_rate_G,\n",
        "                                           beta_1=cfg['adam_beta1_G'],\n",
        "                                           beta_2=cfg['adam_beta2_G'])\n",
        "    optimizer_D = tf.keras.optimizers.Adam(learning_rate=learning_rate_D,\n",
        "                                           beta_1=cfg['adam_beta1_D'],\n",
        "                                           beta_2=cfg['adam_beta2_D'])\n",
        "\n",
        "    # define losses function\n",
        "    pixel_loss_fn = PixelLoss(criterion=cfg['pixel_criterion'])\n",
        "    fea_loss_fn = ContentLoss(criterion=cfg['feature_criterion'])\n",
        "    gen_loss_fn = GeneratorLoss(gan_type=cfg['gan_type'])\n",
        "    dis_loss_fn = DiscriminatorLoss(gan_type=cfg['gan_type'])\n",
        "\n",
        "    # load checkpoint\n",
        "    checkpoint_dir = './checkpoints/' + cfg['sub_name']\n",
        "    checkpoint = tf.train.Checkpoint(step=tf.Variable(0, name='step'),\n",
        "                                     optimizer_G=optimizer_G,\n",
        "                                     optimizer_D=optimizer_D,\n",
        "                                     model=generator,\n",
        "                                     discriminator=discriminator)\n",
        "    manager = tf.train.CheckpointManager(checkpoint=checkpoint,\n",
        "                                         directory=checkpoint_dir,\n",
        "                                         max_to_keep=3)\n",
        "    if manager.latest_checkpoint:\n",
        "        checkpoint.restore(manager.latest_checkpoint)\n",
        "        print('[*] load ckpt from {} at step {}.'.format(\n",
        "            manager.latest_checkpoint, checkpoint.step.numpy()))\n",
        "    else:\n",
        "        if cfg['pretrain_name'] is not None:\n",
        "            pretrain_dir = './checkpoints/' + cfg['pretrain_name']\n",
        "            if tf.train.latest_checkpoint(pretrain_dir):\n",
        "                checkpoint.restore(tf.train.latest_checkpoint(pretrain_dir))\n",
        "                checkpoint.step.assign(0)\n",
        "                print(\"[*] training from pretrain model {}.\".format(\n",
        "                    pretrain_dir))\n",
        "            else:\n",
        "                print(\"[*] cannot find pretrain model {}.\".format(\n",
        "                    pretrain_dir))\n",
        "        else:\n",
        "            print(\"[*] training from scratch.\")\n",
        "\n",
        "    # define training step function\n",
        "    @tf.function\n",
        "    def train_step(lr, hr):\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            sr = generator(lr, training=True)\n",
        "            hr_output = discriminator(hr, training=True)\n",
        "            sr_output = discriminator(sr, training=True)\n",
        "\n",
        "            losses_G = {}\n",
        "            losses_D = {}\n",
        "            losses_G['reg'] = tf.reduce_sum(generator.losses)\n",
        "            losses_D['reg'] = tf.reduce_sum(discriminator.losses)\n",
        "            losses_G['pixel'] = cfg['w_pixel'] * pixel_loss_fn(hr, sr)\n",
        "            losses_G['feature'] = cfg['w_feature'] * fea_loss_fn(hr, sr)\n",
        "            losses_G['gan'] = cfg['w_gan'] * gen_loss_fn(hr_output, sr_output)\n",
        "            losses_D['gan'] = dis_loss_fn(hr_output, sr_output)\n",
        "            total_loss_G = tf.add_n([l for l in losses_G.values()])\n",
        "            total_loss_D = tf.add_n([l for l in losses_D.values()])\n",
        "\n",
        "        grads_G = tape.gradient(\n",
        "            total_loss_G, generator.trainable_variables)\n",
        "        grads_D = tape.gradient(\n",
        "            total_loss_D, discriminator.trainable_variables)\n",
        "        optimizer_G.apply_gradients(\n",
        "            zip(grads_G, generator.trainable_variables))\n",
        "        optimizer_D.apply_gradients(\n",
        "            zip(grads_D, discriminator.trainable_variables))\n",
        "\n",
        "        return total_loss_G, total_loss_D, losses_G, losses_D\n",
        "\n",
        "    # training loop\n",
        "    summary_writer = tf.summary.create_file_writer(\n",
        "        './logs/' + cfg['sub_name'])\n",
        "    prog_bar = ProgressBar(cfg['niter'], checkpoint.step.numpy())\n",
        "    remain_steps = max(cfg['niter'] - checkpoint.step.numpy(), 0)\n",
        "\n",
        "    for lr, hr in train_dataset.take(remain_steps):\n",
        "        checkpoint.step.assign_add(1)\n",
        "        steps = checkpoint.step.numpy()\n",
        "\n",
        "        total_loss_G, total_loss_D, losses_G, losses_D = train_step(lr, hr)\n",
        "\n",
        "        prog_bar.update(\n",
        "            \"loss_G={:.4f}, loss_D={:.4f}, lr_G={:.1e}, lr_D={:.1e}\".format(\n",
        "                total_loss_G.numpy(), total_loss_D.numpy(),\n",
        "                optimizer_G.lr(steps).numpy(), optimizer_D.lr(steps).numpy()))\n",
        "\n",
        "        if steps % 10 == 0:\n",
        "            with summary_writer.as_default():\n",
        "                tf.summary.scalar(\n",
        "                    'loss_G/total_loss', total_loss_G, step=steps)\n",
        "                tf.summary.scalar(\n",
        "                    'loss_D/total_loss', total_loss_D, step=steps)\n",
        "                for k, l in losses_G.items():\n",
        "                    tf.summary.scalar('loss_G/{}'.format(k), l, step=steps)\n",
        "                for k, l in losses_D.items():\n",
        "                    tf.summary.scalar('loss_D/{}'.format(k), l, step=steps)\n",
        "\n",
        "                tf.summary.scalar(\n",
        "                    'learning_rate_G', optimizer_G.lr(steps), step=steps)\n",
        "                tf.summary.scalar(\n",
        "                    'learning_rate_D', optimizer_D.lr(steps), step=steps)\n",
        "\n",
        "        if steps % cfg['save_steps'] == 0:\n",
        "            manager.save()\n",
        "            print(\"\\n[*] save ckpt file at {}\".format(\n",
        "                manager.latest_checkpoint))\n",
        "\n",
        "    print(\"\\n [*] training done!\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(main)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}