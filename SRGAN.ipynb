{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRGAN_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Kjbu34RxdAJM",
        "efUcVAh1dNGC",
        "Duj4rTMTdwME",
        "TUsck_sReZGT"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhipavi/SRGAN/blob/main/SRGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xYbQjUPID31"
      },
      "source": [
        "#NNDL Project\n",
        "Submitted by\n",
        "Abhinav Pavithran(17EC202) and Nadeem Roshan(17EC226)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kjbu34RxdAJM"
      },
      "source": [
        "## **Utilities**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtSivyo2dgZV"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y1Dva0Ocmil"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pickle\n",
        "import skimage.transform\n",
        "import skimage.filters\n",
        "import datetime\n",
        "import os\n",
        "import shutil\n",
        "import math\n",
        "from scipy import misc\n",
        "import scipy.ndimage\n",
        "import glob\n",
        "\n",
        "def process_individual_image(filename_queue, img_size, random_crop=False):\n",
        "  \"\"\"Individual loading & processing for each image\"\"\"\n",
        "  image_file = tf.read_file(filename_queue)\n",
        "  image = tf.image.decode_image(image_file, 3)\n",
        "  if random_crop:\n",
        "    # for training, take a random crop of the image\n",
        "    image_shape = tf.shape(image)\n",
        "    # if smaller than img_size, pad with 0s to prevent error\n",
        "    image = tf.image.pad_to_bounding_box(image, 0, 0, tf.maximum(img_size, image_shape[0]), tf.maximum(img_size, image_shape[1]))\n",
        "    image = tf.random_crop(image, size=[img_size, img_size, 3])\n",
        "    image.set_shape((img_size, img_size, 3))\n",
        "  else:\n",
        "    # for testing, always take a center crop of the image\n",
        "    image = tf.image.resize_image_with_crop_or_pad(image, img_size, img_size)\n",
        "    image.set_shape((img_size, img_size, 3))\n",
        "  return image\n",
        "\n",
        "def build_input_pipeline(filenames, batch_size, img_size, random_crop=False, shuffle=True, num_threads=1):\n",
        "  \"\"\"Builds a tensor which provides randomly sampled pictures from the list of filenames provided\"\"\"\n",
        "  train_file_list = tf.constant(filenames)\n",
        "  filename_queue = tf.train.string_input_producer(train_file_list, shuffle=shuffle)\n",
        "  image = process_individual_image(filename_queue.dequeue(), img_size, random_crop)\n",
        "  image_batch = tf.train.batch([image], batch_size=batch_size,\n",
        "                                           num_threads=num_threads,\n",
        "                                           capacity=10 * batch_size)\n",
        "  return image_batch\n",
        "\n",
        "def build_inputs(args, sess):\n",
        "  if args.overfit:\n",
        "    # Overfit to a single image\n",
        "    train_filenames = np.array(['overfit.png'])\n",
        "    val_filenames = np.array(['overfit.png'])\n",
        "    eval_filenames = np.array(['overfit.png'])\n",
        "    #args.batch_size = 1\n",
        "    args.num_test = 1\n",
        "  else:\n",
        "    # Regular dataset\n",
        "    train_filenames = np.array(glob.glob(os.path.join(args.train_dir, '**', '*.*'), recursive=True))             #hguhuhuhuuhuhuuhuh\n",
        "    val_filenames = np.array(glob.glob(os.path.join('/content/gdrive/MyDrive/SRGAN/Benchmarks', '**', '*_HR.png'), recursive=True))\n",
        "    eval_indices = np.random.randint(len(train_filenames), size=len(val_filenames))\n",
        "    eval_filenames = train_filenames[eval_indices[:119]]\n",
        "  \n",
        "  # Create input pipelines\n",
        "  get_train_batch = build_input_pipeline(train_filenames, batch_size=args.batch_size, img_size=args.image_size, random_crop=True)\n",
        "  get_val_batch = build_input_pipeline(val_filenames, batch_size=args.batch_size, img_size=args.image_size)\n",
        "  get_eval_batch = build_input_pipeline(eval_filenames, batch_size=args.batch_size, img_size=args.image_size)\n",
        "  return get_train_batch, get_val_batch, get_eval_batch\n",
        "\n",
        "def downsample(image, factor):\n",
        "  \"\"\"Downsampling function which matches photoshop\"\"\"\n",
        "  return scipy.misc.imresize(image, 1.0/factor, interp='bicubic')\n",
        "  \n",
        "def downsample_batch(batch, factor):\n",
        "  downsampled = np.zeros((batch.shape[0], batch.shape[1]//factor, batch.shape[2]//factor, 3))\n",
        "  for i in range(batch.shape[0]):\n",
        "    downsampled[i,:,:,:] = downsample(batch[i,:,:,:], factor)\n",
        "  return downsampled\n",
        "\n",
        "def build_log_dir(args, arguments):\n",
        "  \"\"\"Set up a timestamped directory for results and logs for this training session\"\"\"\n",
        "  if args.name:\n",
        "    log_path = args.name #(name + '_') if name else ''\n",
        "  else:\n",
        "    log_path = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "  log_path = os.path.join('results', log_path)\n",
        "  if not os.path.exists(log_path):\n",
        "    os.makedirs(log_path)\n",
        "  print('Logging results for this session in folder \"%s\".' % log_path)\n",
        "  # Output csv header\n",
        "  with open(log_path + '/loss.csv', 'a') as f:\n",
        "    f.write('iteration, val_error, eval_error, set5_psnr, set5_ssim, set14_psnr, set14_ssim, bsd100_psnr, bsd100_ssim\\n')\n",
        "  # Copy this code to folder\n",
        "  shutil.copy2('/content/gdrive/MyDrive/SRGAN/srgan.py', os.path.join(log_path, 'srgan.py'))\n",
        "  shutil.copy2('/content/gdrive/MyDrive/SRGAN/train.py', os.path.join(log_path, 'train.py'))\n",
        "  shutil.copy2('/content/gdrive/MyDrive/SRGAN/utilities.py', os.path.join(log_path, 'utilities.py'))\n",
        "  # Write command line arguments to file\n",
        "  with open(log_path + '/args.txt', 'w+') as f:\n",
        "    f.write(' '.join(arguments))\n",
        "  return log_path\n",
        "\n",
        "def preprocess(lr, hr):\n",
        "  \"\"\"Preprocess lr and hr batch\"\"\"\n",
        "  lr = lr / 255.0\n",
        "  hr = (hr / 255.0) * 2.0 - 1.0\n",
        "  return lr, hr\n",
        "\n",
        "def save_image(path, data, highres=False):\n",
        "  # transform from [-1, 1] to [0, 1]\n",
        "  if highres:\n",
        "    data = (data + 1.0) * 0.5\n",
        "  # transform from [0, 1] to [0, 255], clip, and convert to uint8\n",
        "  data = np.clip(data * 255.0, 0.0, 255.0).astype(np.uint8)\n",
        "  misc.toimage(data, cmin=0, cmax=255).save(path)\n",
        "\n",
        "def evaluate_model(loss_function, get_batch, sess, num_images, batch_size):\n",
        "  \"\"\"Tests the model over all num_images using input tensor get_batch\"\"\"\n",
        "  loss = 0\n",
        "  total = 0\n",
        "  for i in range(int(math.ceil(num_images/batch_size))):\n",
        "    batch_hr = sess.run(get_batch)\n",
        "    batch_lr = downsample_batch(batch_hr, factor=4)\n",
        "    batch_lr, batch_hr = preprocess(batch_lr, batch_hr)\n",
        "    loss += sess.run(loss_function, feed_dict={'g_training:0': False, 'd_training:0': False, 'input_lowres:0': batch_lr, 'input_highres:0':batch_hr})\n",
        "    total += 1\n",
        "  loss = loss / total\n",
        "  return loss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efUcVAh1dNGC"
      },
      "source": [
        "# VGG-19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6QKx9xnc4yn"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "\n",
        "# VGG19 net\n",
        "def vgg_19(inputs,\n",
        "           num_classes=1000,\n",
        "           is_training=False,\n",
        "           dropout_keep_prob=0.5,\n",
        "           spatial_squeeze=True,\n",
        "           scope='vgg_19',\n",
        "           reuse = False,\n",
        "           fc_conv_padding='VALID'):\n",
        "  \"\"\"Oxford Net VGG 19-Layers version E Example.\n",
        "  Note: All the fully_connected layers have been transformed to conv2d layers.\n",
        "        To use in classification mode, resize input to 224x224.\n",
        "  Args:\n",
        "    inputs: a tensor of size [batch_size, height, width, channels].\n",
        "    num_classes: number of predicted classes.\n",
        "    is_training: whether or not the model is being trained.\n",
        "    dropout_keep_prob: the probability that activations are kept in the dropout\n",
        "      layers during training.\n",
        "    spatial_squeeze: whether or not should squeeze the spatial dimensions of the\n",
        "      outputs. Useful to remove unnecessary dimensions for classification.\n",
        "    scope: Optional scope for the variables.\n",
        "    fc_conv_padding: the type of padding to use for the fully connected layer\n",
        "      that is implemented as a convolutional layer. Use 'SAME' padding if you\n",
        "      are applying the network in a fully convolutional manner and want to\n",
        "      get a prediction map downsampled by a factor of 32 as an output. Otherwise,\n",
        "      the output prediction map will be (input / 32) - 6 in case of 'VALID' padding.\n",
        "  Returns:\n",
        "    the last op containing the log predictions and end_points dict.\n",
        "  \"\"\"\n",
        "  with tf.variable_scope(scope, 'vgg_19', [inputs], reuse=reuse) as sc:\n",
        "    end_points_collection = sc.name + '_end_points'\n",
        "    # Collect outputs for conv2d, fully_connected and max_pool2d.\n",
        "    with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],\n",
        "                        outputs_collections=end_points_collection):\n",
        "      net = slim.repeat(inputs, 2, slim.conv2d, 64, 3, scope='conv1', reuse=reuse)\n",
        "      net = slim.max_pool2d(net, [2, 2], scope='pool1')\n",
        "      net = slim.repeat(net, 2, slim.conv2d, 128, 3, scope='conv2',reuse=reuse)\n",
        "      net = slim.max_pool2d(net, [2, 2], scope='pool2')\n",
        "      net = slim.repeat(net, 4, slim.conv2d, 256, 3, scope='conv3', reuse=reuse)\n",
        "      net = slim.max_pool2d(net, [2, 2], scope='pool3')\n",
        "      net = slim.repeat(net, 4, slim.conv2d, 512, 3, scope='conv4',reuse=reuse)\n",
        "      net = slim.max_pool2d(net, [2, 2], scope='pool4')\n",
        "      net = slim.repeat(net, 4, slim.conv2d, 512, 3, scope='conv5',reuse=reuse)\n",
        "      net = slim.max_pool2d(net, [2, 2], scope='pool5')\n",
        "      # Use conv2d instead of fully_connected layers.\n",
        "      # Convert end_points_collection into a end_point dict.\n",
        "      end_points = slim.utils.convert_collection_to_dict(end_points_collection)\n",
        "\n",
        "      return net, end_points"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duj4rTMTdwME"
      },
      "source": [
        "# **Benchmark**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U518Adztdwxr"
      },
      "source": [
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "from scipy import misc\n",
        "from skimage.measure import compare_ssim\n",
        "from skimage.color import rgb2ycbcr,rgb2yuv\n",
        "\n",
        "from skimage.measure import compare_psnr\n",
        "\n",
        "class Benchmark:\n",
        "  \"\"\"A collection of images to test a model on.\"\"\"\n",
        "\n",
        "  def __init__(self, path, name):\n",
        "    self.path = path\n",
        "    self.name = name\n",
        "    #self.images_lr, self.names = self.load_images_by_model(model='LR')\n",
        "    self.images_hr, self.names = self.load_images_by_model(model='HR')\n",
        "    self.images_lr = []\n",
        "    for img in self.images_hr:\n",
        "      self.images_lr.append(downsample(img, 4))\n",
        "    \n",
        "  def load_images_by_model(self, model, file_format='png'):\n",
        "    \"\"\"Loads all images that match '*_{model}.{file_format}' and returns sorted list of filenames and names\"\"\"\n",
        "    # Get files that match the pattern\n",
        "    filenames = sorted(glob.glob(os.path.join(self.path, '*_' + model + '.' + file_format)))\n",
        "    # Extract name/prefix eg: '/.../baby_LR.png' -> 'baby'\n",
        "    names = [os.path.basename(x).split('_')[0] for x in filenames]\n",
        "    return self.load_images(filenames), names\n",
        "\n",
        "  def load_images(self, images):\n",
        "    \"\"\"Given a list of file names, return a list of images\"\"\"\n",
        "    out = []\n",
        "    for image in images:\n",
        "      out.append(misc.imread(image, mode='RGB').astype(np.uint8))\n",
        "    return out\n",
        "\n",
        "  def deprocess(self, image):\n",
        "    \"\"\"Deprocess image output by model (from -1 to 1 float to 0 to 255 uint8)\"\"\"\n",
        "    image = np.clip(255 * 0.5 * (image + 1.0), 0.0, 255.0).astype(np.uint8)\n",
        "    return image\n",
        "\n",
        "  def luminance(self, image):\n",
        "    # Get luminance\n",
        "    lum = rgb2ycbcr(image)[:,:,0]\n",
        "    # Crop off 4 border pixels\n",
        "    lum = lum[4:lum.shape[0]-4, 4:lum.shape[1]-4]\n",
        "    #lum = lum.astype(np.float64)\n",
        "    return lum\n",
        "\n",
        "  def PSNR(self, gt, pred):\n",
        "    #gt = gt.astype(np.float64)\n",
        "    #pred = pred.astype(np.float64)\n",
        "    #mse = np.mean((pred - gt)**2)\n",
        "    #psnr = 10*np.log10(255*255/mse)\n",
        "    #return psnr\n",
        "    return compare_psnr(gt, pred, data_range=255)\n",
        "    \n",
        "  def SSIM(self, gt, pred):\n",
        "    ssim = compare_ssim(gt, pred, data_range=255, gaussian_weights=True)\n",
        "    return ssim\n",
        "    \n",
        "  def test_images(self, gt, pred):\n",
        "    \"\"\"Applies metrics to compare image lists pred vs gt\"\"\"\n",
        "    avg_psnr = 0\n",
        "    avg_ssim = 0\n",
        "    individual_psnr = []\n",
        "    individual_ssim = []\n",
        "\n",
        "    for i in range(len(pred)):\n",
        "      # compare to gt\n",
        "      psnr = self.PSNR(self.luminance(gt[i]), self.luminance(pred[i]))\n",
        "      ssim = self.SSIM(self.luminance(gt[i]), self.luminance(pred[i]))\n",
        "      # save results to log_path ex: 'results/experiment1/Set5/baby/1000.png'\n",
        "      #if save_images:\n",
        "      #  path = os.path.join(log_path, self.name, self.names[i])\n",
        "      # gather results\n",
        "      individual_psnr.append(psnr)\n",
        "      individual_ssim.append(ssim)\n",
        "      avg_psnr += psnr\n",
        "      avg_ssim += ssim\n",
        "    if(len(pred)>0):\n",
        "      avg_psnr /= len(pred)\n",
        "      avg_ssim /= len(pred)\n",
        "    return avg_psnr, avg_ssim, individual_psnr, individual_ssim\n",
        "    \n",
        "  def validate(self):\n",
        "    \"\"\"Tests metrics by using images output by other models\"\"\"\n",
        "    for model in ['bicubic', 'SRGAN-MSE', 'SRGAN-VGG22', 'SRGAN-VGG54', 'SRResNet-MSE', 'SRResNet-VGG22']:\n",
        "      model_output,_ = self.load_images_by_model(model)\n",
        "      psnr, ssim, _, _ = self.test_images(self.images_hr, model_output)\n",
        "      print('Validate %-6s for %-14s: PSNR: %.2f, SSIM: %.4f' % (self.name, model, psnr, ssim))\n",
        "\n",
        "  def save_image(self, image, path):\n",
        "    if not os.path.exists(os.path.split(path)[0]):\n",
        "      os.makedirs(os.path.split(path)[0])\n",
        "    misc.toimage(image, cmin=0, cmax=255).save(path)\n",
        "\n",
        "  def save_images(self, images, log_path, iteration):\n",
        "    count = 0\n",
        "    for output, lr, hr, name in zip(images, self.images_lr, self.images_hr, self.names):\n",
        "      # Save output\n",
        "      path = os.path.join(log_path, self.name, name, '%d_out.png' % iteration)\n",
        "      self.save_image(output, path)\n",
        "      # Save ground truth\n",
        "      if(iteration<1):\n",
        "        path = os.path.join(log_path, self.name, name, '%d_hr.png' % iteration)\n",
        "        self.save_image(hr, path)\n",
        "      # Save low res\n",
        "      if(iteration<1):\n",
        "        path = os.path.join(log_path, self.name, name, '%d_lr.png' % iteration)\n",
        "        self.save_image(lr, path)\n",
        "\n",
        "      # Hack so that we only do first 14 images in BSD100 instead of the whole thing\n",
        "      count += 1\n",
        "      if count >= 3:\n",
        "        break\n",
        "\n",
        "  def evaluate(self, sess, g_y_pred, log_path=None, iteration=0):\n",
        "    \"\"\"Evaluate benchmark, returning the score and saving images.\"\"\"\n",
        "    pred = []\n",
        "    for i, lr in enumerate(self.images_lr):\n",
        "      # feed images 1 by 1 because they have different sizes\n",
        "      lr = lr / 255.0\n",
        "      output = sess.run(g_y_pred, feed_dict={'d_training:0': False, 'g_training:0': False, 'input_lowres:0': lr[np.newaxis]})\n",
        "      # deprocess output\n",
        "      pred.append(self.deprocess(np.squeeze(output, axis=0)))\n",
        "    # save images\n",
        "    if log_path:\n",
        "      self.save_images(pred, log_path, iteration)\n",
        "    return self.test_images(self.images_hr, pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUsck_sReZGT"
      },
      "source": [
        "# **SRGAN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-caBSXReYHl"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class SRGanGenerator:\n",
        "  \"\"\"SRGAN Generator Model from Ledig et. al. 2017\n",
        "  \n",
        "  Reference: https://arxiv.org/pdf/1609.04802.pdf\n",
        "  \"\"\"\n",
        "  def __init__(self, discriminator, training, content_loss='mse', use_gan=True, learning_rate=1e-4, num_blocks=16, num_upsamples=2):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.num_blocks = num_blocks\n",
        "    self.num_upsamples = num_upsamples\n",
        "    self.use_gan = use_gan\n",
        "    self.discriminator = discriminator\n",
        "    self.training = training\n",
        "    self.reuse_vgg = False\n",
        "    if content_loss not in ['mse', 'L1', 'vgg22', 'vgg54']:\n",
        "      print('Invalid content loss function. Must be \\'mse\\', \\'vgg22\\', or \\'vgg54\\'.')\n",
        "      exit()\n",
        "    self.content_loss = content_loss\n",
        "\n",
        "  def ResidualBlock(self, x, kernel_size, filters, strides=1):\n",
        "    \"\"\"Residual block a la ResNet\"\"\"\n",
        "    skip = x\n",
        "    x = tf.layers.conv2d(x, kernel_size=kernel_size, filters=filters, strides=strides, padding='same', use_bias=False)\n",
        "    x = tf.layers.batch_normalization(x, training=self.training)\n",
        "    x = tf.contrib.keras.layers.PReLU(shared_axes=[1,2])(x)\n",
        "    x = tf.layers.conv2d(x, kernel_size=kernel_size, filters=filters, strides=strides, padding='same', use_bias=False)\n",
        "    x = tf.layers.batch_normalization(x, training=self.training)\n",
        "    x = x + skip\n",
        "    return x\n",
        "\n",
        "  def Upsample2xBlock(self, x, kernel_size, filters, strides=1):\n",
        "    \"\"\"Upsample 2x via SubpixelConv\"\"\"\n",
        "    x = tf.layers.conv2d(x, kernel_size=kernel_size, filters=filters, strides=strides, padding='same')\n",
        "    x = tf.depth_to_space(x, 2)\n",
        "    x = tf.contrib.keras.layers.PReLU(shared_axes=[1,2])(x)\n",
        "    return x\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"Builds the forward pass network graph\"\"\"\n",
        "    with tf.variable_scope('generator') as scope:\n",
        "      x = tf.layers.conv2d(x, kernel_size=9, filters=64, strides=1, padding='same')\n",
        "      x = tf.contrib.keras.layers.PReLU(shared_axes=[1,2])(x)\n",
        "      skip = x\n",
        "\n",
        "      # B x ResidualBlocks\n",
        "      for i in range(self.num_blocks):\n",
        "        x = self.ResidualBlock(x, kernel_size=3, filters=64, strides=1)\n",
        "\n",
        "      x = tf.layers.conv2d(x, kernel_size=3, filters=64, strides=1, padding='same', use_bias=False)\n",
        "      x = tf.layers.batch_normalization(x, training=self.training)\n",
        "      x = x + skip\n",
        "\n",
        "      # Upsample blocks\n",
        "      for i in range(self.num_upsamples):\n",
        "        x = self.Upsample2xBlock(x, kernel_size=3, filters=256)\n",
        "      \n",
        "      x = tf.layers.conv2d(x, kernel_size=9, filters=3, strides=1, padding='same', name='forward')\n",
        "      return x\n",
        "      \n",
        "  def vgg_forward(self, x, layer, scope):\n",
        "    # apply vgg preprocessing\n",
        "    # move to range 0-255\n",
        "    x = 255.0 * (0.5 * (x + 1.0))\n",
        "    # subtract means\n",
        "    mean = tf.constant([123.68, 116.779, 103.939], dtype=tf.float32, shape=[1, 1, 1, 3], name='img_mean') # RGB means from VGG paper\n",
        "    x = x - mean\n",
        "    # convert to BGR\n",
        "    x = x[:,:,:,::-1]\n",
        "    # send through vgg19\n",
        "    _,layers = vgg_19(x, is_training=False, reuse=self.reuse_vgg)\n",
        "    self.reuse_vgg = True\n",
        "    return layers[scope + layer]\n",
        "\n",
        "  def _content_loss(self, y, y_pred):\n",
        "    \"\"\"MSE, VGG22, or VGG54\"\"\"\n",
        "    if self.content_loss == 'mse':\n",
        "      return tf.reduce_mean(tf.square(y - y_pred))\n",
        "    if self.content_loss == 'L1':\n",
        "      return tf.reduce_mean(tf.abs(y - y_pred))\n",
        "    if self.content_loss == 'vgg22':\n",
        "      with tf.name_scope('vgg19_1') as scope:\n",
        "        vgg_y = self.vgg_forward(y, 'vgg_19/conv2/conv2_2', scope)\n",
        "      with tf.name_scope('vgg19_2') as scope:\n",
        "        vgg_y_pred = self.vgg_forward(y_pred, 'vgg_19/conv2/conv2_2', scope)\n",
        "      return 0.006*tf.reduce_mean(tf.square(vgg_y - vgg_y_pred)) + 2e-8*tf.reduce_sum(tf.image.total_variation(y_pred))\n",
        "      \n",
        "    if self.content_loss == 'vgg54':\n",
        "      with tf.name_scope('vgg19_1') as scope:\n",
        "        vgg_y = self.vgg_forward(y, 'vgg_19/conv5/conv5_4', scope)\n",
        "      with tf.name_scope('vgg19_2') as scope:\n",
        "        vgg_y_pred = self.vgg_forward(y_pred, 'vgg_19/conv5/conv5_4', scope)\n",
        "      return 0.006*tf.reduce_mean(tf.square(vgg_y - vgg_y_pred))\n",
        "\n",
        "  def _adversarial_loss(self, y_pred):\n",
        "    \"\"\"For GAN.\"\"\"\n",
        "    y_discrim, y_discrim_logits = self.discriminator.forward(y_pred)\n",
        "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=y_discrim_logits, labels=tf.ones_like(y_discrim_logits)))\n",
        "\n",
        "  def loss_function(self, y, y_pred):\n",
        "    \"\"\"Loss function\"\"\"\n",
        "    if self.use_gan:\n",
        "      # Weighted sum of content loss and adversarial loss\n",
        "      return self._content_loss(y, y_pred) + 1e-3*self._adversarial_loss(y_pred)\n",
        "    # Content loss only\n",
        "    return self._content_loss(y, y_pred)\n",
        "  \n",
        "  def optimize(self, loss):\n",
        "    #tf.control_dependencies([discrim_train\n",
        "    # update_ops needs to be here for batch normalization to work\n",
        "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope='generator')\n",
        "    with tf.control_dependencies(update_ops):\n",
        "      return tf.train.AdamOptimizer(self.learning_rate).minimize(loss, var_list=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator'))\n",
        "\n",
        "\n",
        "class SRGanDiscriminator:\n",
        "  \"\"\"SRGAN Discriminator Model from Ledig et. al. 2017\n",
        "  \n",
        "  Reference: https://arxiv.org/pdf/1609.04802.pdf\n",
        "  \"\"\"\n",
        "  def __init__(self, training, learning_rate=1e-4, image_size=96):\n",
        "    self.graph_created = False\n",
        "    self.learning_rate = learning_rate\n",
        "    self.training = training\n",
        "    self.image_size = image_size\n",
        "\n",
        "  def ConvolutionBlock(self, x, kernel_size, filters, strides):\n",
        "    \"\"\"Conv2D + BN + LeakyReLU\"\"\"\n",
        "    x = tf.layers.conv2d(x, kernel_size=kernel_size, filters=filters, strides=strides, padding='same', use_bias=False)\n",
        "    x = tf.layers.batch_normalization(x, training=self.training)\n",
        "    x = tf.contrib.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "    return x\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"Builds the forward pass network graph\"\"\"\n",
        "    with tf.variable_scope('discriminator') as scope:\n",
        "      # Reuse variables when graph is applied again\n",
        "      if self.graph_created:\n",
        "        scope.reuse_variables()\n",
        "      self.graph_created = True\n",
        "\n",
        "      # Image dimensions are fixed to the training size because of the FC layer\n",
        "      x.set_shape([None, self.image_size, self.image_size, 3])\n",
        "\n",
        "      x = tf.layers.conv2d(x, kernel_size=3, filters=64, strides=1, padding='same')\n",
        "      x = tf.contrib.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "      x = self.ConvolutionBlock(x, 3, 64, 2)\n",
        "      x = self.ConvolutionBlock(x, 3, 128, 1)\n",
        "      x = self.ConvolutionBlock(x, 3, 128, 2)\n",
        "      x = self.ConvolutionBlock(x, 3, 256, 1)\n",
        "      x = self.ConvolutionBlock(x, 3, 256, 2)\n",
        "      x = self.ConvolutionBlock(x, 3, 512, 1)\n",
        "      x = self.ConvolutionBlock(x, 3, 512, 2)\n",
        "\n",
        "      x = tf.contrib.layers.flatten(x)\n",
        "      x = tf.layers.dense(x, 1024)\n",
        "      x = tf.contrib.keras.layers.LeakyReLU(alpha=0.2)(x)\n",
        "      logits = tf.layers.dense(x, 1)\n",
        "      x = tf.sigmoid(logits)\n",
        "      return x, logits\n",
        "\n",
        "  def loss_function(self, y_real_pred, y_fake_pred, y_real_pred_logits, y_fake_pred_logits):\n",
        "    \"\"\"Discriminator wants to maximize log(y_real) + log(1-y_fake).\"\"\"\n",
        "    loss_real = tf.reduce_mean(tf.losses.sigmoid_cross_entropy(tf.ones_like(y_real_pred_logits), y_real_pred_logits))\n",
        "    loss_fake = tf.reduce_mean(tf.losses.sigmoid_cross_entropy(tf.zeros_like(y_fake_pred_logits), y_fake_pred_logits))\n",
        "    return loss_real + loss_fake\n",
        "\n",
        "  def optimize(self, loss):\n",
        "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS, scope='discriminator')\n",
        "    with tf.control_dependencies(update_ops):\n",
        "      return tf.train.AdamOptimizer(self.learning_rate).minimize(loss, var_list=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='discriminator'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYogo_mmeo1l"
      },
      "source": [
        "# **Train**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfricpH3sHHH",
        "outputId": "042b35cc-4d54-4b46-e0b1-b998b0c7da3e"
      },
      "source": [
        "print(scipy.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZZBRoa4leMa",
        "outputId": "7930d183-4750-4bd4-bd0d-aa33b3625863"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqPb5Yq3inP0"
      },
      "source": [
        "class arguments:\n",
        "    load =  '/content/gdrive/MyDrive/SRGAN/logfolder/weights-28000'\n",
        "    load_gen=None\n",
        "    name = '/content/gdrive/MyDrive/SRGAN/logfolder' \n",
        "    overfit = False \n",
        "    batch_size = 16\n",
        "    log_freq = 1000\n",
        "    learning_rate=1e-4\n",
        "    content_loss ='mse'\n",
        "    use_gan=True\n",
        "    image_size=92\n",
        "    vgg_weights='/content/gdrive/MyDrive/SRGAN/vgg_19.ckpt'\n",
        "    train_dir = '/content/gdrive/MyDrive/SRGAN/Train'\n",
        "    validate_benchmarks = False \n",
        "    gpu = '0' \n",
        "args = arguments()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TgvkJCtGen5X",
        "outputId": "9e34d2e5-7d18-49cd-855c-3368ebee39a2"
      },
      "source": [
        "  import tensorflow as tf\n",
        "  from tensorflow.python.training import queue_runner\n",
        "  import numpy as np\n",
        "  import os\n",
        "  import sys\n",
        "  tf.reset_default_graph()\n",
        "  os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "\n",
        "  \n",
        "\n",
        "  \n",
        "  # Set up models\n",
        "  d_training = tf.placeholder(tf.bool, name='d_training')\n",
        "  g_training = tf.placeholder(tf.bool, name='g_training')\n",
        "  discriminator = SRGanDiscriminator(training=g_training, image_size=args.image_size)\n",
        "  generator = SRGanGenerator(discriminator=discriminator, training=d_training, learning_rate=args.learning_rate, content_loss=args.content_loss, use_gan=args.use_gan)\n",
        "  # Generator\n",
        "  g_x = tf.placeholder(tf.float32, [None, None, None, 3], name='input_lowres')\n",
        "  g_y = tf.placeholder(tf.float32, [None, None, None, 3], name='input_highres')\n",
        "  g_y_pred = generator.forward(g_x)\n",
        "  g_loss = generator.loss_function(g_y, g_y_pred)\n",
        "  g_train_step = generator.optimize(g_loss)\n",
        "  # Discriminator\n",
        "  d_x_real = tf.placeholder(tf.float32, [None, None, None, 3], name='input_real')\n",
        "  d_y_real_pred, d_y_real_pred_logits = discriminator.forward(d_x_real)\n",
        "  d_y_fake_pred, d_y_fake_pred_logits = discriminator.forward(g_y_pred)\n",
        "  d_loss = discriminator.loss_function(d_y_real_pred, d_y_fake_pred, d_y_real_pred_logits, d_y_fake_pred_logits)\n",
        "  d_train_step = discriminator.optimize(d_loss)\n",
        "  \n",
        "  # Set up benchmarks\n",
        "  benchmarks = [Benchmark('/content/gdrive/MyDrive/SRGAN/Benchmarks/BSD100', name='BSD100')]\n",
        "  if args.validate_benchmarks:\n",
        "    for benchmark in benchmarks:\n",
        "      benchmark.validate()\n",
        "\n",
        "  # Create log folder\n",
        "  if args.load and not args.name:\n",
        "    log_path = os.path.dirname(args.load)\n",
        "  else:\n",
        "    log_path = build_log_dir(args, sys.argv)\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "    # Build input pipeline\n",
        "    get_train_batch, get_val_batch, get_eval_batch = build_inputs(args, sess)\n",
        "    # Initialize\n",
        "    sess.run(tf.local_variables_initializer())\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    # Start input pipeline thread(s)\n",
        "    coord = tf.train.Coordinator()\n",
        "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
        "    \n",
        "    # Load saved weights\n",
        "    iteration = 0\n",
        "    saver = tf.train.Saver()\n",
        "    # Load generator\n",
        "    if args.load_gen:\n",
        "      gen_saver = tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='generator'))\n",
        "      iteration = int(args.load_gen.split('-')[-1])\n",
        "      gen_saver.restore(sess, args.load_gen)\n",
        "    # Load all\n",
        "    if args.load:\n",
        "      iteration = int(args.load.split('-')[-1])\n",
        "      saver.restore(sess, args.load)\n",
        "    # Load VGG\n",
        "    if 'vgg' in args.content_loss:\n",
        "      vgg_saver = tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope='vgg_19'))\n",
        "      vgg_saver.restore(sess, args.vgg_weights)\n",
        "\n",
        "    # Train\n",
        "    while True:\n",
        "      if iteration % args.log_freq == 0:\n",
        "        # Test every log-freq iterations\n",
        "        val_error = evaluate_model(g_loss, get_val_batch, sess, 119, args.batch_size)\n",
        "        eval_error = evaluate_model(g_loss, get_eval_batch, sess, 119, args.batch_size)\n",
        "        # Log error\n",
        "        print('[%d] Test: %.7f, Train: %.7f' % (iteration, val_error, eval_error), end='')\n",
        "        # Evaluate benchmarks\n",
        "        log_line = ''\n",
        "        for benchmark in benchmarks:\n",
        "          psnr, ssim, _, _ = benchmark.evaluate(sess, g_y_pred, log_path, iteration)\n",
        "          print(' [%s] PSNR: %.2f, SSIM: %.4f' %( benchmark.name, psnr, ssim), end='')\n",
        "          log_line += ',%.7f, %.7f' %(psnr, ssim)\n",
        "        print()\n",
        "        # Write to log\n",
        "        with open(log_path + '/loss.csv', 'a') as f:\n",
        "          f.write('%d, %.15f, %.15f%s\\n' % (iteration, val_error, eval_error, log_line))\n",
        "        # Save checkpoint\n",
        "        saver.save(sess, os.path.join(log_path, 'weights'), global_step=iteration, write_meta_graph=False)\n",
        "\n",
        "      # Train discriminator\n",
        "      if args.use_gan:\n",
        "        batch_hr = sess.run(get_train_batch)\n",
        "        batch_lr = downsample_batch(batch_hr, factor=2)\n",
        "        batch_lr, batch_hr = preprocess(batch_lr, batch_hr)\n",
        "        sess.run(d_train_step, feed_dict={d_training: True, g_training: True, g_x: batch_lr, g_y: batch_hr, d_x_real: batch_hr})\n",
        "      # Train generator\n",
        "      batch_hr = sess.run(get_train_batch)\n",
        "      batch_lr = downsample_batch(batch_hr, factor=2)\n",
        "      batch_lr, batch_hr = preprocess(batch_lr, batch_hr)\n",
        "      sess.run(g_train_step, feed_dict={d_training: True, g_training: True, g_x: batch_lr, g_y: batch_hr})\n",
        "\n",
        "      iteration += 1\n",
        "      if(iteration%100==0):\n",
        "        print(\"Iteration:\",iteration)\n",
        "\n",
        "    # Stop queue threads\n",
        "    coord.request_stop()\n",
        "    coord.join(threads)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: DeprecationWarning: `imread` is deprecated!\n",
            "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use ``imageio.imread`` instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:64: DeprecationWarning: `imresize` is deprecated!\n",
            "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.3.0.\n",
            "Use Pillow instead: ``numpy.array(Image.fromarray(arr).resize())``.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Logging results for this session in folder \"/content/gdrive/MyDrive/SRGAN/logfolder\".\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/MyDrive/SRGAN/logfolder/weights-28000\n",
            "[28000] Test: 0.0263971, Train: 0.0266956"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:96: DeprecationWarning: `toimage` is deprecated!\n",
            "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
            "Use Pillow's ``Image.fromarray`` directly instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:56: UserWarning: DEPRECATED: skimage.measure.compare_psnr has been moved to skimage.metrics.peak_signal_noise_ratio. It will be removed from skimage.measure in version 0.18.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:59: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " [BSD100] PSNR: 25.49, SSIM: 0.6543\n",
            "Iteration: 28100\n",
            "Iteration: 28200\n",
            "Iteration: 28300\n",
            "Iteration: 28400\n",
            "Iteration: 28500\n",
            "Iteration: 28600\n",
            "Iteration: 28700\n",
            "Iteration: 28800\n",
            "Iteration: 28900\n",
            "Iteration: 29000\n",
            "[29000] Test: 0.0256794, Train: 0.0231129 [BSD100] PSNR: 26.36, SSIM: 0.6799\n",
            "Iteration: 29100\n",
            "Iteration: 29200\n",
            "Iteration: 29300\n",
            "Iteration: 29400\n",
            "Iteration: 29500\n",
            "Iteration: 29600\n",
            "Iteration: 29700\n",
            "Iteration: 29800\n",
            "Iteration: 29900\n",
            "Iteration: 30000\n",
            "[30000] Test: 0.0244063, Train: 0.0252296 [BSD100] PSNR: 25.96, SSIM: 0.6643\n",
            "Iteration: 30100\n",
            "Iteration: 30200\n",
            "Iteration: 30300\n",
            "Iteration: 30400\n",
            "Iteration: 30500\n",
            "Iteration: 30600\n",
            "Iteration: 30700\n",
            "Iteration: 30800\n",
            "Iteration: 30900\n",
            "Iteration: 31000\n",
            "[31000] Test: 0.0246546, Train: 0.0261465 [BSD100] PSNR: 25.79, SSIM: 0.6464\n",
            "Iteration: 31100\n",
            "Iteration: 31200\n",
            "Iteration: 31300\n",
            "Iteration: 31400\n",
            "Iteration: 31500\n",
            "Iteration: 31600\n",
            "Iteration: 31700\n",
            "Iteration: 31800\n",
            "Iteration: 31900\n",
            "Iteration: 32000\n",
            "[32000] Test: 0.0282151, Train: 0.0274004 [BSD100] PSNR: 25.36, SSIM: 0.6291\n",
            "Iteration: 32100\n",
            "Iteration: 32200\n",
            "Iteration: 32300\n",
            "Iteration: 32400\n",
            "Iteration: 32500\n",
            "Iteration: 32600\n",
            "Iteration: 32700\n",
            "Iteration: 32800\n",
            "Iteration: 32900\n",
            "Iteration: 33000\n",
            "[33000] Test: 0.0240733, Train: 0.0243952 [BSD100] PSNR: 26.43, SSIM: 0.6949\n",
            "Iteration: 33100\n",
            "Iteration: 33200\n",
            "Iteration: 33300\n",
            "Iteration: 33400\n",
            "Iteration: 33500\n",
            "Iteration: 33600\n",
            "Iteration: 33700\n",
            "Iteration: 33800\n",
            "Iteration: 33900\n",
            "Iteration: 34000\n",
            "[34000] Test: 0.0259380, Train: 0.0214669 [BSD100] PSNR: 26.20, SSIM: 0.6779\n",
            "Iteration: 34100\n",
            "Iteration: 34200\n",
            "Iteration: 34300\n",
            "Iteration: 34400\n",
            "Iteration: 34500\n",
            "Iteration: 34600\n",
            "Iteration: 34700\n",
            "Iteration: 34800\n",
            "Iteration: 34900\n",
            "Iteration: 35000\n",
            "[35000] Test: 0.0280045, Train: 0.0328307 [BSD100] PSNR: 24.84, SSIM: 0.6286\n",
            "Iteration: 35100\n",
            "Iteration: 35200\n",
            "Iteration: 35300\n",
            "Iteration: 35400\n",
            "Iteration: 35500\n",
            "Iteration: 35600\n",
            "Iteration: 35700\n",
            "Iteration: 35800\n",
            "Iteration: 35900\n",
            "Iteration: 36000\n",
            "[36000] Test: 0.0346046, Train: 0.0298060 [BSD100] PSNR: 24.94, SSIM: 0.5986\n",
            "Iteration: 36100\n",
            "Iteration: 36200\n",
            "Iteration: 36300\n",
            "Iteration: 36400\n",
            "Iteration: 36500\n",
            "Iteration: 36600\n",
            "Iteration: 36700\n",
            "Iteration: 36800\n",
            "Iteration: 36900\n",
            "Iteration: 37000\n",
            "[37000] Test: 0.0230348, Train: 0.0229836 [BSD100] PSNR: 26.51, SSIM: 0.6937\n",
            "Iteration: 37100\n",
            "Iteration: 37200\n",
            "Iteration: 37300\n",
            "Iteration: 37400\n",
            "Iteration: 37500\n",
            "Iteration: 37600\n",
            "Iteration: 37700\n",
            "Iteration: 37800\n",
            "Iteration: 37900\n",
            "Iteration: 38000\n",
            "[38000] Test: 0.0323707, Train: 0.0309175 [BSD100] PSNR: 24.64, SSIM: 0.6021\n",
            "Iteration: 38100\n",
            "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.CancelledError'>, Enqueue operation was cancelled\n",
            "\t [[{{node batch_2/fifo_queue_enqueue}}]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-a2b004b8fb9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     95\u001b[0m       \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_train_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0md_training\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_training\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_x\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_y\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_hr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_x_real\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_hr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# Train generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0mbatch_hr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_train_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m     \u001b[0mbatch_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownsample_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_hr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mbatch_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_hr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_hr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OqICDz2g8xl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}